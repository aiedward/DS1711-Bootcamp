{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(CONFIDENTIAL) INTERNAL USE ONLY, NOT FOR EXTERNAL DISTRIBUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias and Varience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the physical law says: S = 1/2 * F / M * t*2\n",
    "# S: displacement, M: mass, F: force\n",
    "# Let's say we know nothing about physics\n",
    "# Given this data measure points: \n",
    "# (t, S) for N points, we want to predict for (t_new) what is S_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth_coef = 1./2 * 10 / 2\n",
    "t = np.random.random(10) * 3\n",
    "ground_truth_result = ground_truth_coef * t**2\n",
    "\n",
    "# measure error\n",
    "measure_result = ground_truth_result + np.random.randn(10)*2\n",
    "\n",
    "t_new = np.random.random(5) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics\n",
    "lm_lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Under fitting, what is the error? (using 1 order)\n",
    "# we need to run it over multple times to see the difference\n",
    "N = 10000\n",
    "error = []\n",
    "error_train = []\n",
    "for i in range(N):\n",
    "    t = np.random.random(10) * 3\n",
    "    ground_truth_result = ground_truth_coef * t**2\n",
    "    measure_result = ground_truth_result + np.random.randn(10)*2\n",
    "    t.resize([len(t), 1])\n",
    "    \n",
    "    lm_lr.fit(t, measure_result)\n",
    "    \n",
    "    t_new = (np.random.random(5) * 3).reshape(-1, 1)\n",
    "    t_truth = ground_truth_coef * t_new[:,0]**2\n",
    "    t_pred = lm_lr.predict(t_new)\n",
    "    \n",
    "    error.append(metrics.mean_squared_error(t_pred, t_truth))\n",
    "    #error_train.append(metrics.mean_squared_error(t, measure_result))\n",
    "    \n",
    "error = np.array(error)\n",
    "#error_train = np.array(error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print error_train.mean(), error_train.std()\n",
    "print error.mean(), error.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Over fitting, what is the error? (using 3 order)\n",
    "N = 10000\n",
    "error = []\n",
    "for i in range(N):\n",
    "    t = (np.random.random(10) * 3).reshape([-1, 1])\n",
    "    ground_truth_result = ground_truth_coef * t**2\n",
    "    measure_result = ground_truth_result + (np.random.randn(10)*2).reshape([-1,1])\n",
    "    t = np.hstack([t, t**2, t**3])\n",
    "    \n",
    "    lm_lr.fit(t, measure_result)\n",
    "    \n",
    "    t_new = (np.random.random(5)).reshape([-1, 1])\n",
    "    t_new = np.hstack([t_new, t_new**2, t_new**3])\n",
    "    t_truth = ground_truth_coef * t_new[:,0]**2\n",
    "    t_pred = lm_lr.predict(t_new)\n",
    "    \n",
    "    error.append(metrics.mean_squared_error(t_pred, t_truth))\n",
    "    #error_train.append(metrics.mean_squared_error(t[:,0], measure_result))\n",
    "\n",
    "    \n",
    "error = np.array(error)\n",
    "#error_train = np.array(error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print error.mean(), error.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Over fitting, what is the error? (using 2 order)\n",
    "N = 10000\n",
    "error = []\n",
    "for i in range(N):\n",
    "    t = (np.random.random(10) * 3).reshape([-1, 1])\n",
    "    ground_truth_result = ground_truth_coef * t**2\n",
    "    measure_result = ground_truth_result + (np.random.randn(10)*2).reshape([-1,1])\n",
    "    t = np.hstack([t, t**2])\n",
    "    \n",
    "    lm_lr.fit(t, measure_result)\n",
    "    \n",
    "    t_new = (np.random.random(5)).reshape([-1, 1])\n",
    "    t_new = np.hstack([t_new, t_new**2])\n",
    "    t_truth = ground_truth_coef * t_new[:,0]**2\n",
    "    t_pred = lm_lr.predict(t_new)\n",
    "    \n",
    "    error.append(metrics.mean_squared_error(t_pred, t_truth))\n",
    "    \n",
    "error = np.array(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print error.mean(), error.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Balance Varience & Bias\n",
    "np.random.seed(1)\n",
    "x = (np.random.random([30, 1]) * 6 - 4).ravel()\n",
    "y = -2*(5*x)**3 - 30 * (5*x) **2 + 100*(10*x) + 500 * np.random.randn(len(x))\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1. Under ALL circumstances, is it that the more complicated a model is, the lower training error? \n",
    "# Q2. Under ALL circumstances, is it that the more complicated a model is, the lower testing error? \n",
    "# Q3. How does standard deviation looks like for both training & testing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias & varience: model complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single variable linear model (low varience)\n",
    "\n",
    "# nearest-neighbour model (high varience) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q. is single linear regression model high bias, low varience? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data set 1. \n",
    "N = 300\n",
    "np.random.seed(1)\n",
    "x = (np.random.random([N, 1]) * 6 - 4).ravel()\n",
    "y = -2*(5*x)**3 - 30 * (5*x) **2 + 100*(10*x) + 500 * np.random.randn(len(x))\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data set 2. \n",
    "N = 5000\n",
    "r = np.random.rand(N)\n",
    "theta = np.random.rand(N) * 1.0 * np.pi\n",
    "y = np.sin(theta) * r\n",
    "plt.scatter(r, theta, c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias & varience: data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.make_regression(n_samples=1000, n_features=100, n_informative=100, noise=100)\n",
    "X = data[0]\n",
    "Y = data[1]\n",
    "print X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_range = np.arange(0.05, 1, 0.05)\n",
    "N_run = 50\n",
    "t_score = []\n",
    "v_score = []\n",
    "for train_s in ts_range:\n",
    "    t_score.append([])\n",
    "    v_score.append([])\n",
    "    for iseed in range(N_run):\n",
    "        X1, X2, Y1, Y2 = cross_validation.train_test_split(X, Y, train_size=train_s, random_state=iseed)\n",
    "        rlm = linear_model.LinearRegression()\n",
    "        rlm.fit(X1, Y1)\n",
    "        t_score[-1].append(metrics.r2_score(Y1, rlm.predict(X1)))\n",
    "        v_score[-1].append(metrics.r2_score(Y2, rlm.predict(X2)))\n",
    "    # print train_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_score = np.array(t_score)\n",
    "v_score = np.array(v_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# errorbar plot (training and validation)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "x = range(t_score.shape[0])[2:]\n",
    "y = t_score.mean(axis=1)[2:]\n",
    "s = t_score.std(axis=1)[2:]\n",
    "ax.errorbar(x, y, yerr=s)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# errorbar plot (training and validation)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "x = range(t_score.shape[0])[2:]\n",
    "y = t_score.mean(axis=1)[2:]\n",
    "s = t_score.std(axis=1)[2:]\n",
    "ax.errorbar(x, y, yerr=s)\n",
    "x = range(v_score.shape[0])[2:]\n",
    "y = v_score.mean(axis=1)[2:]\n",
    "s = v_score.std(axis=1)[2:]\n",
    "ax.errorbar(x, y, yerr=s)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression in-depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regular linear regression\n",
    "\n",
    "# Lasso\n",
    "\n",
    "# Ridge\n",
    "\n",
    "# Elastic-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X is the 10x10 Hilbert matrix\n",
    "X = 1. / (np.arange(1, 11) + np.arange(0, 10)[:, np.newaxis])\n",
    "y = np.ones(10)\n",
    "data = datasets.make_regression(n_samples=100, n_features=10, n_informative=10, random_state=0)\n",
    "\n",
    "X = data[0]\n",
    "y = data[1]\n",
    "\n",
    "###############################################################################\n",
    "# Compute paths\n",
    "\n",
    "n_alphas = 200\n",
    "alphas = np.logspace(-1, 5, n_alphas)\n",
    "clf = linear_model.Ridge()\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    clf.set_params(alpha=a)\n",
    "    clf.fit(X, y)\n",
    "    coefs.append(clf.coef_)\n",
    "\n",
    "###############################################################################\n",
    "# Display results\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_color_cycle(['b', 'r', 'g', 'c', 'k', 'y', 'm'])\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Compute paths\n",
    "\n",
    "n_alphas = 200\n",
    "alphas = np.logspace(-1, 5, n_alphas)\n",
    "clf = linear_model.Lasso()\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    clf.set_params(alpha=a)\n",
    "    clf.fit(X, y)\n",
    "    coefs.append(clf.coef_)\n",
    "\n",
    "###############################################################################\n",
    "# Display results\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_color_cycle(['b', 'r', 'g', 'c', 'k', 'y', 'm'])\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Lasso coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Compute paths\n",
    "\n",
    "n_alphas = 200\n",
    "alphas = np.logspace(-1, 5, n_alphas)\n",
    "clf = linear_model.ElasticNet(l1_ratio=0.5)\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    clf.set_params(alpha=a)\n",
    "    clf.fit(X, y)\n",
    "    coefs.append(clf.coef_)\n",
    "\n",
    "###############################################################################\n",
    "# Display results\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_color_cycle(['b', 'r', 'g', 'c', 'k', 'y', 'm'])\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('ES coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Excercise, run the regression over friedman datasets, see which variables are selected at different alpha\n",
    "data = datasets.make_friedman1(random_state=0)\n",
    "X = data[0]\n",
    "y = data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://vis.supstat.com/2013/03/gradient-descent-algorithm-with-r/\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.make_regression(n_samples=10000, n_features=1000, n_informative=1000)\n",
    "X = data[0]\n",
    "y = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare efficiency and accuracy for SGD and tradition LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lrg1 = linear_model.LinearRegression()\n",
    "lrg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lrg2 = linear_model.SGDRegressor()\n",
    "lrg2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = datasets.make_regression(n_samples=1000, n_features=2, n_informative=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = X\n",
    "X2 = X.copy()\n",
    "X2[:,1] *= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = linear_model.LinearRegression()\n",
    "m1.fit(X1, Y)\n",
    "\n",
    "m2 = linear_model.LinearRegression()\n",
    "m2.fit(X2, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77.2136552 ,  88.18939999])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77.2136552,   0.0881894])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = linear_model.SGDRegressor()\n",
    "m1.fit(X1, Y)\n",
    "\n",
    "m2 = linear_model.SGDRegressor()\n",
    "m2.fit(X2, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 77.19276286,  88.15315519]), array([ 0.01569117]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.coef_, m1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001999487193715426"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(m1.predict(X1), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -1.54393637e+11,   5.94092367e+11]), array([ -1.33254479e+11]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coef_, m2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5607337515545333e+29"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(m2.predict(X2), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why robustness is needed?\n",
    "\n",
    "x = np.random.random(100) * 10 \n",
    "y = 2.0 * x + 30 + 2.0 * np.random.rand(len(x))\n",
    "\n",
    "xn = np.random.random(10) * 3\n",
    "yn = 6.0 * xn + 4 + 2.0 * np.random.rand(len(xn))\n",
    "\n",
    "xnew = np.concatenate([x,xn])\n",
    "ynew = np.concatenate([y,yn])\n",
    "\n",
    "xnew = xnew.reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RANSAC\n",
    "# https://upload.wikimedia.org/wikipedia/commons/c/c0/RANSAC_LINIE_Animiert.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
